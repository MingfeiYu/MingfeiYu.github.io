<div align=center><img src="./Pics/MingfeiYu_pic.jpg" alt="MingfeiYu" title="Profile photo" width="540"/></div>
  
## Biography
Mingfei Yu (郁 明非) is currently a first year master candidate at Electrical Engineering and Information Systems, Graduate School of Engineering, University of Tokyo, Japan, under the supervision of [Prof. Masahiro Fujita](https://www.cad.t.u-tokyo.ac.jp/professor.html). His research interest includes the sw/hw co-design for accelerating the execution of deep neural network models, scheduling algorithms for the parallelization of modern deep learning implementations, and CAD(logic synthesis, verification, etc) for VLSI. 

- [Resume (Last Update: Aug. 2021)](https://drive.google.com/file/d/1T9qSalYAFf0MWmTyDRye07Wz1GNvLL6R/view?usp=sharing)

## Education 
- Mar. 2020 - Present: Master candidate at EEIS, Graduate School of Engineering, University of Tokyo
- Sept. 2019 - Feb. 2020: Research student at EEIS, Graduate School of Engineering, University of Tokyo
- Sept. 2015 - June 2019: Bachelor at Department of Electrical Engineering, Zhejiang University, China

## Publications
### [ASPDAC'21] A Decomposition-Based Synthesis Algorithm for Sparse Matrix-Vector Multiplication in Parallel Communication Structure
- __Mingfei Yu__, Ruitao Gao and Masahiro Fujita
### [DATE'21] Logic Synthesis for Generalization and Learning Addition
- Yukio Miyasaka, Xinpei Zhang, __Mingfei Yu__, Qingyang Yi and Masahiro Fujita
### [IEICE VLSI Design Technologies(VLD)'21] Scheduling Sparse Matrix-Vector Multiplication onto Parallel Communication Architecture
- __Mingfei Yu__, Ruitao Gao and Masahiro Fujita ,'' in IEICE VLSI Design Technologies(VLD) 2021. 

## Awards & Scholarships
### 2021
- **Best Poster Award** among 38 Computing and Communication Systems postgraduate students in UTokyo
- **3rd Place** on **Programming Contest at IWLS: Machine Learning & Logic Synthesis**
- **Excellent Student Author Award** at **IEICE VLD** 
### 2020
- **Honorable Mention(4th Place)** on **CAD Contest at ICCAD: X-value Equivalence Checking**
- **Best Video Award** at **DAC Young Fellow Program**
- **DAC Young Fellow Member**
- **1st Place** on **Programming Contest at IWLS: Machine Learning & Logic Synthesis**

## Research Experience
### Graduate Research Assistant
Fujita Lab, University of Tokyo, Tokyo, Japan
- Feb. 2020 - present
- Advisor: Prof. Masahiro Fujita
- **Parallel Scheduling of Modern Deep Learning Implementations**: Compile typical modern deep leanringimplementations, including convolution computations in CNN models and self-attention mechanism in Transformermodels, onto a unidirectional ring-connected parallel computing architecture, to realize their high performance processing.Based on this work, a paper is accepted by ASP-DAC 2021, while another is under review at ASP-DAC 2022. 
- **Low-Precision Quantization for BERT Model**: Propose quantization techniques to reduce the number of bitsrequired for data representation in BERT, the recently most popular model for natural language processing tasks, withnegligible model performance loss. A paper based on this work is under review at ASP-DAC 2022. 
### Graduate Research Assistant
AIST-UTokyo AI chip Design open innovation Laboratory, Tokyo, Japan
- Sept. 2020 - Mar. 2021
- Advisor: Prof. Masahiro Fujita and Dr. Shinichi O'uchi
- **A Flexible CNN Accelerator on top of FPGA**: An FPGA-based flexible accelerator design for the execution of various CNN models is proposed. According to experimental results on a platform with highly limited hardware resources(Zedboard, developed by AVNET), our design is able to achieve up to 99.8\% MAC utilization for computations in each convolution layer during the execution of VGG-16. 
### Visiting Student (Remote)
Computer Systems Lab, Cornell University, Ithaca, New York, USA
- June 2021 - July 2021
- Advisor: Prof. Zhiru Zhang
- **Hardware Implementation for Overwrite Quantization**: A low-cost hardware design supporting the handling of opportunistic outliers is proposed as an expander to existing systolic array-based neural network accelerators. 

## Work Experience
### Research Intern
System-ASIC, NVIDIA, Shanghai, China
- **Research on error checking and correction(ECC) algorithms and their hardware implementations**: Surveyand design ECC algorithms meeting the demands of next generation of NVIDIA desktop GPU products, as well as realize their hardware implementations. High-level synthesis techniques are adopted in this project.
